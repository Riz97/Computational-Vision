{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoder"
      ],
      "metadata": {
        "id": "PrUp8Wv6jVZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import main libraries"
      ],
      "metadata": {
        "id": "GxN3J61LqMDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "eNawaWpJqJNn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Autoencoders are a data compression algorithms made up of a compression and decompression functions.\n",
        "Two interesting practical applications of autoencoders are data denoising, and dimensionality reduction for data visualization. \n",
        "\n",
        " The lab is organized as following:\n",
        "\n",
        "  1.1 Dataset loading;\n",
        "\n",
        "  1.2 Pre-processing (Dataset normalization, splitting and label pre-processing; \n",
        "\n",
        "  1.3 Deep Autoencoder implementation;\n",
        "\n",
        "  1.4 Autoencoder training;\n",
        "\n",
        "  1.5 Autoencoder testing.\n",
        "\n",
        "\n",
        "  Similarly with a Convolutional Autoencoder.\n",
        "\n",
        "  You will visualize the latent representation and use such method for image denoising with synthetic noise.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "lRDpr0vl2zly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data\n",
        "Load the data you want experiment with (e.g. fashion and mnist). Experiment with different dataset, how the architectures should be changed? Do you notice any difference in the results (e.g. in terms of the loss function)?"
      ],
      "metadata": {
        "id": "ArISuFDzqQgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "rZdHPk95qQsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize and add one channel.\n",
        "One common practice in training a Neural Network is to normalize the images by dividing each pixel value by the maximum value that we can have.<br> The purpose of this is to obtain a mean close to 0.<br>\n",
        "Normalizing the data generally speeds up learning and leads to faster convergence"
      ],
      "metadata": {
        "id": "iNvCeOSX3lbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(array):\n",
        "    \"\"\"\n",
        "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
        "    \"\"\"\n",
        "    array = array.astype(\"float32\") / # Fill here#\n",
        "    \n",
        "    # add 1 channel\n",
        "    array = np.reshape(array, (len(array), # Fill here #))\n",
        "    return array\n",
        "\n",
        "# Normalize and reshape the data\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "zw0d4sPV292R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize data"
      ],
      "metadata": {
        "id": "Rz84CkPmwn_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_imgs(imgs, n= 20):\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(imgs[i])\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plot_imgs(x_train)"
      ],
      "metadata": {
        "id": "hE9ksBD5wnBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Deep Autoencoder with Dense layers\n",
        "\n",
        "Models in Keras are defined as a sequence of layers. The things to choose when defining the architecture are many:\n",
        " - number of layers\n",
        " - type of layers\n",
        " - size of layers\n",
        " - type of non-linearity (activation functions)\n",
        " - whether or not to add regularization\n",
        " \n",
        "Here we will use only fully-connected (dense) layers, so the type of layer is fixed. Fully connected layers are defined using the [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) class, which takes as parameters the number of neurons (which is the **dimension of the output**).\n",
        "\n",
        "The following image is sketch of the general architecure:\n",
        "\n",
        "![Deep Autoencoder](https://www.compthree.com/images/blog/ae/ae.png)\n"
      ],
      "metadata": {
        "id": "q0pY8y_fqke0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a class extending [Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model), then we define the [sequence](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) of layers for both encoder and decoder. Note than the Encoder and Decoder  should be as symmetric as possible. "
      ],
      "metadata": {
        "id": "3wPg_i215mwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim   \n",
        "\n",
        "\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(latent_dim, activation='relu'),\n",
        "    ])\n",
        "\n",
        "    \n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(784, activation='sigmoid'),\n",
        "      layers.Reshape((28, 28))\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n"
      ],
      "metadata": {
        "id": "ZNBdUPs4qne6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile model\n",
        "\n",
        "Define the autoencoder of fully connected layers.\n",
        "After having created a model you need to **compile** it. During the compilation phase you must specify some parameters related to how the model will be optimized:\n",
        " - The `optimizer`. For the following exercise you should use [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD), initialized with some learning rate.\n",
        " - The `loss` function. For the reconstruction you can use the [mean squared error](https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredError) loss.\n",
        " - A list of `metrics`: common error functions which you want keras to report at each training epoch.\n",
        "\n"
      ],
      "metadata": {
        "id": "roAXypgq0-nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 10\n",
        "autoencoder = Autoencoder( latent_dim)\n",
        "\n",
        "#  set optimizer and loss function\n",
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n"
      ],
      "metadata": {
        "id": "fZQlO9RxqqV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 5\n",
        "history = autoencoder.fit(x_train, x_train,\n",
        "                epochs=epochs,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "_oKEJeJGrPR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the loss function for each epoch for both validation and traning data. See [History](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)."
      ],
      "metadata": {
        "id": "CLc4p7PrzSbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  plt.plot(loss, marker=\"o\", c=\"red\", label='Training loss')\n",
        "  plt.plot(val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "y-2zzPsizVtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the learnt model on the test set."
      ],
      "metadata": {
        "id": "OFchx1sD8tyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n"
      ],
      "metadata": {
        "id": "Jn9fmLMxt6mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_examples(x_test, decoded_imgs, n = 10):\n",
        "  \n",
        "  plt.figure(figsize=(20, 4))\n",
        "  for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title(\"original\")\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i])\n",
        "    plt.title(\"reconstructed\")\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "  plt.show()\n",
        "\n",
        "plot_examples(x_test,decoded_imgs )"
      ],
      "metadata": {
        "id": "SG2l3l-QuCwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the latent representation. If it is 2-dimensional plot as it is, otherwise apply PCA dimensionality reduction. Try to visualize the points with a different color for each class, what do you observe?"
      ],
      "metadata": {
        "id": "TFpRxztX1spL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pca_latent_space(encoded_imgs, labels):\n",
        "\n",
        "  pca = PCA(n_components=2)\n",
        "  data_reduced = pca.fit_transform(encoded_imgs)\n",
        "\n",
        "  x, y = data_reduced[..., 0], data_reduced[..., 1]\n",
        "\n",
        "  plt.figure(figsize=(8, 6), dpi=80)\n",
        "  plt.scatter(x, y, c=labels, cmap='viridis')\n",
        "  plt.title(\"Representation wrt labels\")\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "\n",
        "def plot_latent_space(encoded_imgs, labels):\n",
        "\n",
        "  assert encoded_imgs.shape[-1] ==2\n",
        "\n",
        "  x, y = encoded_imgs[..., 0], encoded_imgs[..., 1]\n",
        "\n",
        "  plt.figure(figsize=(8, 6), dpi=80)\n",
        "  plt.scatter(x, y, c=labels, cmap='viridis')\n",
        "  plt.title(\"Representation wrt labels\")\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "\n",
        "if latent_dim==2:\n",
        "  plot_latent_space(encoded_imgs, y_test)\n",
        "else:\n",
        "  plot_pca_latent_space(encoded_imgs, y_test)"
      ],
      "metadata": {
        "id": "uAqcptpoQ640"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will scan the latent plane, sampling latent points at regular intervals, and generating the corresponding image for each of these points. This gives us a visualization of the latent manifold that \"generates\" the data."
      ],
      "metadata": {
        "id": "EOEDz81-_pgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_manifold(decoder, n=15):\n",
        "  # Display a 2D manifold of the digits\n",
        "  n = 15  # figure with 15x15 digits\n",
        "  img_size = 28\n",
        "  figure = np.zeros((img_size * n, img_size * n))\n",
        "  # We will sample n points within [-15, 15] standard deviations\n",
        "  grid_x = np.linspace(-15, 15, n)\n",
        "  grid_y = np.linspace(-15, 15, n)\n",
        "\n",
        "  for i, yi in enumerate(grid_x):\n",
        "      for j, xi in enumerate(grid_y):\n",
        "          z_sample = np.array([[xi, yi]])\n",
        "          print(z_sample.shape)\n",
        "          x_decoded = decoder.predict(z_sample)\n",
        "          digit = x_decoded[0].reshape(img_size, img_size)\n",
        "          figure[i * img_size: (i + 1) * img_size,\n",
        "               j * img_size: (j + 1) * img_size] = digit\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.imshow(figure)\n",
        "  plt.show()\n",
        "\n",
        "if latent_dim==2:\n",
        "  plot_manifold(autoencoder.decoder)"
      ],
      "metadata": {
        "id": "a0Nwze1w_IMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment with different latent dimensions and comment the results you obtain.\n",
        "You may try different architectures. \n",
        "We ask you to add one layer, again,discuss the results."
      ],
      "metadata": {
        "id": "odjv7P8WtJs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Autoencoder with Convolutional layers\n",
        "\n",
        "we are going to create a convolutional model in Keras. \n",
        "Usually a convolutional model is made by two subsequent part:\n",
        "* A convolutional part\n",
        "* A fully connected\n",
        "\n",
        "We can show an example of the general structure in the next picture:\n",
        "\n",
        "![Convolutional autoencoder](https://149695847.v2.pressablecdn.com/wp-content/uploads/2020/07/The-structure-of-proposed-Convolutional-AutoEncoders-CAE-for-MNIST-In-the-middle-there.png)\n",
        "\n",
        "\n",
        "\n",
        "Usually the convolutional part is made by some layers composed by\n",
        "* convolutional layer: performs a spatial convolution over images\n",
        "* pooling layer: used to reduce the output spatial dimension from $n$ to 1 by averaging the $n$ different value or considering the maximum between them \n",
        "* dropout layer: applied to a layer, consists of randomly \"dropping out\" (i.e. set to zero) a number of output features of the layer during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "pF21Vht_9Uhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement a Model as you have done for the deep autoencoder. Here try to use Convolutions, Batch Normalizations and Pooling layers.\n",
        "\n",
        "The Decoder should be specular to the Encoder, therefore the Convolutional layers should be replaced with [Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose)"
      ],
      "metadata": {
        "id": "HFSf0OMH7r38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ConvAutoencoder(Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(ConvAutoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim   \n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      # Fill here #\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "     # Fill here #\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ],
      "metadata": {
        "id": "S_5kgbDwDLfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 64 \n",
        "autoencoder = ConvAutoencoder(latent_dim)\n",
        "\n",
        "#  set optimizer and loss function\n",
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "epochs = 10\n",
        "history = autoencoder.fit(x_train, x_train,\n",
        "                epochs=epochs,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "L12-P5pgFUAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "BYKcBoEc6_tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_examples(x_test,decoded_imgs )\n",
        "\n"
      ],
      "metadata": {
        "id": "mHun_0ZqUPIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if latent_dim==2:\n",
        "  plot_latent_space(encoded_imgs, y_test)\n",
        "else:\n",
        "  plot_pca_latent_space(encoded_imgs, y_test)"
      ],
      "metadata": {
        "id": "bhZLsRASW-we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you see any difference between the Deep Autoencoder and the Convolutional one? Training time, Reconstruction loss, Complexity of the model (e.g. number of parameters)."
      ],
      "metadata": {
        "id": "5c6pw-Pd7-QL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Denoising (optional)\n",
        "\n",
        "Let's put our convolutional autoencoder to work on an image denoising problem. It's simple: we will train the autoencoder to map noisy images to clean images.\n",
        "\n",
        "Here's how we will generate synthetic noisy images: we just apply a gaussian noise matrix and clip the images between 0 and 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "ItGk_4rLut8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(img, noise_factor = 0.5):\n",
        "  # add gaussian noise\n",
        "  img_noisy = img + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=img.shape) \n",
        "  img_noisy = np.clip(img_noisy, 0., 1.)\n",
        "  return img_noisy\n",
        "\n",
        "x_train_noisy = add_noise(x_train)\n",
        "x_test_noisy = add_noise(x_test)"
      ],
      "metadata": {
        "id": "be5OMXaUu-Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 64 \n",
        "autoencoder = ConvAutoencoder(latent_dim)\n",
        "\n",
        "#  set optimizer and loss function\n",
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "epochs = 10\n",
        "autoencoder.fit(# fill here #\n",
        "                , # fill here# ,\n",
        "                epochs=epochs,\n",
        "                shuffle=True,\n",
        "                validation_data=(\n",
        "                    #fill here#\n",
        "                ))"
      ],
      "metadata": {
        "id": "iAFhvoMHwBXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K1dBcVw4u9iZ"
      }
    }
  ]
}